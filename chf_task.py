# -*- coding: utf-8 -*-
"""CHF_Task.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h_5HFNq91HvVU4mrLnHKiIsVhxta6X21
"""

# important libaraies
import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt

# data uploading
data = pd.read_csv("/content/EGX_DLY_COMI, 1D.csv")
df = pd.DataFrame(data)

df.head(60)

"""Data information for data type and Descriptive statistical analysis"""

df.info()

df.describe()

df.isnull().sum()

df.isna().mean()

df['date'] = pd.to_datetime(df['time'] , unit = 's')
df['date']
df.head(5)

df.drop('time' , inplace = True , axis = 1)

df.head(5)

df.info()

df.describe()

"""Datatime domain converting"""

df['year'] = (df['date']).dt.year
df['month'] = df['date'].dt.month
df['day'] = df['date'].dt.day
df.drop('date' , inplace = True , axis = 1)
df.head(2)

sns.boxplot(df['high'])

(df['high'] > 75).sum()

"""New data without outliers"""

new_df = df[df['high'] <= 70]
new_df

sns.boxplot(new_df['high'])

def remove_outliers(col_data):
  outliers = col_data - col_data.mean() / col_data.std()
  threshold = 75
  filtered_col = df[outliers <= threshold]
  return filtered_col
remove_outliers(df['high'])

from matplotlib import pyplot as plt
df['high'].plot(kind='hist', bins=20, title='high')
plt.gca().spines[['top', 'right',]].set_visible(False)

from matplotlib import pyplot as plt
import seaborn as sns
def _plot_series(series, series_name, series_index=0):
  from matplotlib import pyplot as plt
  import seaborn as sns
  palette = list(sns.palettes.mpl_palette('Dark2'))
  xs = series['year']
  ys = series['open']

  plt.plot(xs, ys, label=series_name, color=palette[series_index % len(palette)])

fig, ax = plt.subplots(figsize=(10, 5.2), layout='constrained')
df_sorted = df.sort_values('year', ascending=True)
_plot_series(df_sorted, '')
sns.despine(fig=fig, ax=ax)
plt.xlabel('year')
_ = plt.ylabel('open')

from matplotlib import pyplot as plt
df['low'].plot(kind='hist', bins=20, title='low')
plt.gca().spines[['top', 'right',]].set_visible(False)

sns.pairplot(new_df)

"""Random Forest Algorithm with new_df


---


"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error , mean_absolute_error
from sklearn.model_selection import GridSearchCV,RandomizedSearchCV

x = df.drop('high' , axis = 1)
x

x = x = new_df.drop('high' , axis = 1)
y = new_df['high']

from sklearn.model_selection import train_test_split
x_train , x_test , y_train , y_test = train_test_split(x , y , test_size = 0.25 , random_state = 0)
x_train.shape

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

model = RandomForestRegressor()
model.fit(x_train, y_train)

# predict the mode
y_pred = model.predict(x_test)
error = y_test-y_pred
error.mean()

Y_data = pd.DataFrame({'Tested_value' : y_test , 'predicted_value' : y_pred})
Y_data

param_grid = {
    'n_estimators': [25, 50, 100, 150],
    'max_features': ['sqrt', 'log2', None],
    'max_depth': [3, 6, 9],
    'max_leaf_nodes': [3, 6, 9],
}

grid_search = GridSearchCV(RandomForestRegressor(),
                           param_grid=param_grid)
grid_search.fit(x_train, y_train)
print(grid_search.best_estimator_)

model_grid = RandomForestRegressor(max_depth=6,
									max_features="log2",
									max_leaf_nodes=9,
									n_estimators=100)
model_grid.fit(x_train, y_train)
y_pred_grid = model.predict(x_test)
new_error = y_test - y_pred
new_error.mean()

new_Y_data = pd.DataFrame({'Tested_value' : y_test , 'predicted_value' : y_pred})
new_Y_data

import matplotlib.pyplot as plt
plt.scatter(new_Y_data['predicted_value'], new_Y_data['Tested_value'])
plt.xlabel('Predicted Value')
_ = plt.ylabel('Tested Value')

from matplotlib import pyplot as plt
new_Y_data['Tested_value'].plot(kind='hist', bins=20, title='Tested_value')
plt.gca().spines[['top', 'right',]].set_visible(False)

def evalute_metric(x , y):
  mse = mean_squared_error(x , y)
  mbs = mean_absolute_error(x , y)
  return mse , mbs
evalute_metric(y_test , y_pred)

"""Randomforest algorithm with Orignal data

"""

x = x = df.drop('high' , axis = 1)
y = df['high']

from sklearn.model_selection import train_test_split
x_train , x_test , y_train , y_test = train_test_split(x , y , test_size = 0.25 , random_state = 0)
x_train.shape

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

model = RandomForestRegressor()
model.fit(x_train, y_train)

# predict the mode
y_pred = model.predict(x_test)
error = y_test-y_pred
error.mean()

Y_data = pd.DataFrame({'Tested_value' : y_test , 'predicted_value' : y_pred})
Y_data

param_grid = {
    'n_estimators': [25, 50, 100, 150],
    'max_features': ['sqrt', 'log2', None],
    'max_depth': [3, 6, 9],
    'max_leaf_nodes': [3, 6, 9],
}

grid_search = GridSearchCV(RandomForestRegressor(),
                           param_grid=param_grid)
grid_search.fit(x_train, y_train)
print(grid_search.best_estimator_)

model_grid = RandomForestRegressor(max_depth=6,
									max_features="log2",
									max_leaf_nodes=9,
									n_estimators=25)
model_grid.fit(x_train, y_train)
y_pred_grid = model.predict(x_test)
new_error = y_test - y_pred
new_error.mean()

new_Y_data = pd.DataFrame({'Tested_value' : y_test , 'predicted_value' : y_pred})
new_Y_data

import matplotlib.pyplot as plt
plt.scatter(new_Y_data['predicted_value'], new_Y_data['Tested_value'])
plt.xlabel('Predicted Value')
_ = plt.ylabel('Tested Value')

from matplotlib import pyplot as plt
new_Y_data['Tested_value'].plot(kind='hist', bins=20, title='Tested_value')
plt.gca().spines[['top', 'right',]].set_visible(False)

def evalute_metric(x , y):
  mse = mean_squared_error(x , y)
  mbs = mean_absolute_error(x , y)
  return mse , mbs
evalute_metric(y_test , y_pred)